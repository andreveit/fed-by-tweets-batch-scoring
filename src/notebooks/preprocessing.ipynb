{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/andre/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "from enelvo.normaliser import Normaliser\n",
    "from collections import Counter\n",
    "import spacy\n",
    "# !python -m spacy download pt_core_news_sm\n",
    "import langdetect\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 80)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk_stopwords = set(stopwords.words('portuguese'))\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language(s):\n",
    "    try:\n",
    "        return langdetect.detect(s)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Treat Users\n",
    "def treat_users(tweet_tkz, frequent_users):\n",
    "    '''\n",
    "    Apply functions to treat users\n",
    "    '''\n",
    "    tweet_tkz = remove_ats_frequet_users(tweet_tkz, frequent_users)\n",
    "    return remove_users(tweet_tkz)\n",
    "\n",
    "\n",
    "\n",
    "def get_users_rank(corpus, limit = 40):\n",
    "    '''\n",
    "    Returns rank (list of tuples) of most the frequent users in the corpus\n",
    "    '''\n",
    "    frame = pd.DataFrame({'corpus': corpus})\n",
    "    frame = frame[frame.corpus.str.contains('@')]\n",
    "    frame['at_'] = frame.corpus.apply(lambda doc: [word for word in doc.split() if '@' in word])\n",
    "    flatten = [num for elem in frame.at_.tolist() for num in elem]\n",
    "    rank = Counter(flatten).most_common(limit)\n",
    "    \n",
    "    return rank\n",
    "\n",
    "\n",
    "\n",
    "def get_frequent_users(corpus, limit=40):\n",
    "    rank = get_users_rank(corpus, limit)\n",
    "    return [i for i,j in rank]\n",
    "\n",
    "\n",
    "\n",
    "def remove_ats_frequet_users(tweet_tkz, frequent_users):\n",
    "    '''\n",
    "    Remove ats from frequent users, so they are kept in the corpus.\n",
    "    '''\n",
    "    intersection_set = set(tweet_tkz).intersection(set(frequent_users))\n",
    "    if len(intersection_set) != 0 :\n",
    "        for user in intersection_set:\n",
    "            tweet_tkz = [token.replace('@','')  if token == user else token for token in tweet_tkz]\n",
    "    return tweet_tkz\n",
    "\n",
    "\n",
    "def remove_users(tweet_tkz):\n",
    "    '''\n",
    "    Remove users with @.\n",
    "    '''\n",
    "    tweet = re.sub('@[^\\s]+','user',' '.join(tweet_tkz))\n",
    "    tweet_tkz = [token for token in tweet.split(' ') if token != 'user']\n",
    "    return tweet_tkz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Processing Emojis\n",
    "\n",
    "def remove_brs(tweet_tkz, replacement = 'brasil'):\n",
    "    '''\n",
    "    After tokenazation 🇧🇷 are turned into '🇧', '🇷'. Replacing them for \"brasil\".\n",
    "    '''\n",
    "    for i, _ in enumerate(tweet_tkz):\n",
    "        if tweet_tkz[i] in ('🇧','🇷'):\n",
    "            if i+1 <= len(tweet_tkz):\n",
    "                if tweet_tkz[i+1] in ('🇧','🇷'):\n",
    "                    tweet_tkz[i] = replacement\n",
    "                    tweet_tkz[i+1] = ''\n",
    "    tweet_tkz = [i for i in tweet_tkz if i != '']\n",
    "    return tweet_tkz\n",
    "\n",
    "\n",
    "# Emojis\n",
    "\n",
    "\n",
    "def treat_emojis(tweet_tkz, top_rank_emjs):\n",
    "    '''\n",
    "    Replaces or removes emojis from tokenized tweet.\n",
    "    The result depends on the frequency emojis rank and available translations. \n",
    "    '''\n",
    "    all_emjs = emoji.UNICODE_EMOJI['pt'] \n",
    "\n",
    "    new_tweet_tkz = []\n",
    "    for token in tweet_tkz:\n",
    "        if token in top_rank_emjs:\n",
    "            new_tweet_tkz.append(top_rank_emjs[token])\n",
    "        elif token in all_emjs:\n",
    "\n",
    "            pass\n",
    "        else:\n",
    "            new_tweet_tkz.append(token)\n",
    "    return new_tweet_tkz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_top_rank_emjs(corpus, limit=40, filename='../../data/3-preprocessed/emojis_dict.json'):\n",
    "    '''\n",
    "    Return translation dictionary for the most frequent emojis\n",
    "    '''\n",
    "    emojs_translation = get_emojis_words(corpus, limit, filename)\n",
    "    top_rank_emjs = [i for i, _ in get_emojis_rank(corpus)]\n",
    "    return { k:v for k,v in  emojs_translation.items() if k in top_rank_emjs} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_emojis_words(corpus, limit=40, filename='../../data/3-preprocessed/emojis_dict.json'):\n",
    "    '''\n",
    "    Return a dict mapping emojis and their respective word to be replaced in the documents.\n",
    "    '''\n",
    "    with open(filename, 'r') as file:\n",
    "        translations = json.load(file)\n",
    "    \n",
    "    emjs_dict = emoji.UNICODE_EMOJI['pt'] \n",
    "\n",
    "    return { emoji: translations.get(item.replace(':',''))\n",
    "            for emoji, item in emjs_dict.items() \n",
    "            if translations.get(item.replace(':','')) is not None \n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_emojis_rank(corpus, limit=40):\n",
    "    '''\n",
    "    Rank the most frequent emotions in the corpus.\n",
    "    Return a list of tuples.\n",
    "    '''\n",
    "    list_of_lists = [extract_emojis(token) for token in corpus if not isinstance(extract_emojis(token), float)]\n",
    "    flat_list = [item for sublist in list_of_lists for item in sublist]\n",
    "    c = Counter(flat_list)\n",
    "    return c.most_common(limit)\n",
    "\n",
    "\n",
    "def extract_emojis(tweet):\n",
    "    '''\n",
    "    Return a list of emotions in a tweet.\n",
    "    '''\n",
    "    emjs_dict = emoji.UNICODE_EMOJI['pt'] \n",
    "    emjs = []\n",
    "    tweet_tkz = tknzr.tokenize(tweet)\n",
    "    for token in tweet_tkz:\n",
    "        if token in emjs_dict:\n",
    "            emjs.append(token)\n",
    "    if len(emjs)==0:\n",
    "        return np.nan\n",
    "    return emjs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_stopwords(tweet_tkz, filename = '../../data/3-preprocessed/stopwords.json'):\n",
    "    ''' \n",
    "    Load stopwords list from file and remove them from tokenized tweets.\n",
    "    '''\n",
    "    with open(filename, 'r') as file:\n",
    "        stopwords = json.load(file)\n",
    "        \n",
    "    stopwords = nltk_stopwords.union(set(stopwords))\n",
    "    return [token for token in tweet_tkz if token.lower() not in stopwords]\n",
    "\n",
    "\n",
    "\n",
    "def treat_kkk(tweet_tkz):\n",
    "    ''' \n",
    "    Replace laugh kkkk for \"risada\".\n",
    "    '''\n",
    "    return [ 'risada'  if token in ['kkk'+i*'k' for i in range(25)] else token for token in tweet ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split joined words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_joined_words(token):\n",
    "    '''\n",
    "    Rertuns a list of splited tokens if splitable.\n",
    "    '''\n",
    "    if not token.isupper():\n",
    "        return re.sub( r\"([A-Z])\", r\" \\1\", token).split()\n",
    "\n",
    "    return [token]\n",
    "\n",
    "\n",
    "def tokenize_joined_words(tweet_tkz):\n",
    "    ''' \n",
    "    Tokenize words without spaces.\n",
    "    '''\n",
    "    new_tweet_tkz = []\n",
    "    for token in tweet_tkz:\n",
    "        token = split_joined_words(token)\n",
    "        for sub_token in token:\n",
    "            new_tweet_tkz.append(sub_token)\n",
    "    \n",
    "    return new_tweet_tkz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESSING WHOLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99  %\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "# Load Data\n",
    "\n",
    "reload_data = False\n",
    "\n",
    "if reload_data:\n",
    "    twt = pd.read_parquet('../../data/1-raw/tweets.parquet')\n",
    "    places = pd.read_parquet('../../data/1-raw/places.parquet')\n",
    "    users = pd.read_parquet('../../data/1-raw/users.parquet')\n",
    "\n",
    "\n",
    "    twt['is_retweet'] = np.where(twt.text.str.contains('RT @'),1,0)\n",
    "    twt['created_at_date'] = twt.created_at.dt.date\n",
    "    twt['created_at_time'] = twt.created_at.dt.time\n",
    "\n",
    "    twt['emoji'] = twt.text.apply(lambda x: extract_emojis(x))\n",
    "    twt.emoji = twt.emoji.apply(lambda x: ''.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "    twt['lang'] = twt.text.apply(lambda x: get_language(x))\n",
    "    twt.to_pickle('../../data/2-intermediate/tweets.pkl')\n",
    "\n",
    "else:\n",
    "    twt = pd.read_pickle('../../data/2-intermediate/tweets.pkl')\n",
    "    df = twt[twt.is_retweet == 0]\n",
    "    df = df.drop(columns=['import_date','file_name'])\n",
    "    df = df[df.lang=='pt']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "corpus = df.text.tolist()\n",
    "top_rank_emjs = get_top_rank_emjs(corpus)\n",
    "frequent_users = get_frequent_users(corpus)\n",
    "\n",
    "norm = Normaliser(tokenizer='readable')\n",
    "spc = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "\n",
    "bag = []\n",
    "for i, tweet in enumerate(corpus):\n",
    "    clear_output(wait=True)\n",
    "    print(round(i/len(corpus)*100,2), \" %\")\n",
    "\n",
    "    tknzr = TweetTokenizer()\n",
    "\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','url',tweet)\n",
    "\n",
    "    tweet = tweet.replace('R$','reais').replace('-','').replace('url','')\n",
    "    tweet = tknzr.tokenize(tweet)\n",
    "    tweet = treat_users(tweet, frequent_users)\n",
    "\n",
    "    tweet = treat_emojis(tweet, top_rank_emjs)\n",
    "\n",
    "    tweet = remove_brs(tweet)\n",
    "\n",
    "    tweet = remove_stopwords(tweet)\n",
    "\n",
    "    tweet = re.sub(r'[^\\w\\s]','',' '.join(tweet)).split(' ') # Usar por ultimo pois retira emojis\n",
    "    tweet = [token for token in tweet if token != ''] # remove empty strings\n",
    "\n",
    "    tweet = [token.lemma_.lower() for token in spc(' '.join(tweet))]\n",
    "    \n",
    "    tweet = treat_kkk(tweet)\n",
    "\n",
    "    tweet = tokenize_joined_words(tweet)\n",
    "\n",
    "    tweet = norm.normalise(' '.join([token.lower() for token in tweet])).split(' ')\n",
    "\n",
    "    tweet = remove_stopwords(tweet)\n",
    "\n",
    "    tweet = [token if token != 'suboficial' else 'lulaoficial' for token in tweet ]\n",
    "    tweet = [token if token != 'vagar' else 'vagabundo' for token in tweet ]\n",
    "    tweet = [token if token != 'firsar' else 'risada' for token in tweet ]\n",
    "\n",
    "    bag.append(tweet)\n",
    "\n",
    "\n",
    "df_processed = pd.DataFrame({'text':bag})\n",
    "df_processed.to_pickle('../../data/2-intermediate/corpus.plk')\n",
    "\n",
    "df_processed = pd.concat([df.reset_index(drop=True), df_processed.rename(columns={'text':'tokens'})], axis=1)\n",
    "df_processed.to_parquet('../../data/2-intermediate/tweets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>place_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>created_at_date</th>\n",
       "      <th>created_at_time</th>\n",
       "      <th>emoji</th>\n",
       "      <th>lang</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1542153434534641665</td>\n",
       "      <td>2022-06-29 14:30:05+00:00</td>\n",
       "      <td>1251632043764703245</td>\n",
       "      <td>@Jouberth19 #com Bolsonaro juntos</td>\n",
       "      <td>97bcdfca1a2dca59</td>\n",
       "      <td>bolsonaro</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>14:30:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>[bolsonaro, junto]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1542153432106164226</td>\n",
       "      <td>2022-06-29 14:30:04+00:00</td>\n",
       "      <td>1341510046929346566</td>\n",
       "      <td>Toyjo: “Desde o início do governo Bolsonaro, Brasil recebeu cerca de R$ ... https://t.co/lADVL6POXT via @YouTube</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>bolsonaro</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>14:30:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>[tojo, desde, início, governo, bolsonaro, brasil, receber, cerca, real, youtube]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1542153431401521153</td>\n",
       "      <td>2022-06-29 14:30:04+00:00</td>\n",
       "      <td>1469115605257048064</td>\n",
       "      <td>@Eduardomg_95 Isso aqui que é fazer um Governo sem roubalheira ou corrupção. Governo Bolsonaro! Bolsonaro reeleito. https://t.co/64Wx5beI4Q</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>bolsonaro</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>14:30:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>[aqui, governo, roubalheira, corrupção, governo, bolsonaro, bolsonaro, reeleger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1542153431137361923</td>\n",
       "      <td>2022-06-29 14:30:04+00:00</td>\n",
       "      <td>42459902</td>\n",
       "      <td>DESMENTINDO BOLSONARO \n",
       "Serviço de Utilidade Pública https://t.co/pv8ekLSo7W</td>\n",
       "      <td>68e019afec7d0ba5</td>\n",
       "      <td>bolsonaro</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>14:30:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>[desmentindo, bolsonaro, serviço, utilidade, pública]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1542153429098831873</td>\n",
       "      <td>2022-06-29 14:30:03+00:00</td>\n",
       "      <td>1395125418651435011</td>\n",
       "      <td>@UOLNoticias Acho engraçado os bolsominions justificando que é pra atingir o governo Bolsonaro. Faz o seguinte, põe sua mãe ou sua filha pra trabalhar com ele então e deixa ele colocar as mãos nas partes íntimas delas, depois justifica que elas estão reclamando pra atingir o governo Bolsonaro</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>bolsonaro</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>14:30:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>[monotipia, achar, engraçar, homofóbicos, justificar, atingir, governo, bolsonaro, faz, seguinte, pôr, mãe, filha, trabalhar, deixar, colocar, mão, partes, íntima, justificar, reclamar, atingir, governo, bolsonaro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18642</th>\n",
       "      <td>1544447539071619073</td>\n",
       "      <td>2022-07-05 22:26:02+00:00</td>\n",
       "      <td>346927346</td>\n",
       "      <td>@lsentoes1 Será que o mito também não estaria pensando assim? O Lula veio na frente e Jair acabou perdendo o contato. E olha que o Jair sair primeiro heim.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>lula</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-05</td>\n",
       "      <td>22:26:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>[mito, pensar, assim, lula, frente, jair, acabar, perder, contato, olhar, jair, sair, primeiro, heim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18643</th>\n",
       "      <td>1544447519601479680</td>\n",
       "      <td>2022-07-05 22:25:57+00:00</td>\n",
       "      <td>58943137</td>\n",
       "      <td>@Anaceli65806423 @ThiagoResiste Pelo mesmo motivo ao qual o Lula não foi preso antes.. imunidade parlamentar.\n",
       "Mas não se preocupe. Todos eles dividirão celas em breve...lula dorme embaixo e bozo em cima.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>lula</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-05</td>\n",
       "      <td>22:25:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>[thiagoresiste, motivo, lula, prender, antes, imunidade, parlamentar, preocupe, dividir, cela, breve, lula, dorme, embaixo, bozó, cima]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18644</th>\n",
       "      <td>1544447517965926401</td>\n",
       "      <td>2022-07-05 22:25:57+00:00</td>\n",
       "      <td>1443602071</td>\n",
       "      <td>Coloca guardiões do Lula nisso\n",
       "#STFOrganizacaoCriminosa https://t.co/lJAy31dbe9</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>lula</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-05</td>\n",
       "      <td>22:25:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>[colocar, guardião, lula, stforganizacaocriminoso]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18645</th>\n",
       "      <td>1544447516057501696</td>\n",
       "      <td>2022-07-05 22:25:56+00:00</td>\n",
       "      <td>727669276207923200</td>\n",
       "      <td>@JanainaDoBrasil Eu tb elogio o presidente Lula assim.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>lula</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-05</td>\n",
       "      <td>22:25:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>[janainadobrasil, elogio, presidente, lula, assim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18646</th>\n",
       "      <td>1544447506188324864</td>\n",
       "      <td>2022-07-05 22:25:54+00:00</td>\n",
       "      <td>67869026</td>\n",
       "      <td>Os mesmos que querem que eu tenha empatia com Mario Frias sāo aqueles que comemoraram a morte do neto de Lula e de Dona Marisa Leticia. Vāo pro o inferno demônios Bolsonaristas! Nāo tenho empatia por nazifacista!</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>lula</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-05</td>\n",
       "      <td>22:25:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pt</td>\n",
       "      <td>[empatar, mario, frias, comemorar, morte, neto, lula, dona, marisa, letícia, vão, inferno, demônio, bolsonaristas, neo, empatar, nazifascista]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18647 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                created_at            author_id  \\\n",
       "0      1542153434534641665 2022-06-29 14:30:05+00:00  1251632043764703245   \n",
       "1      1542153432106164226 2022-06-29 14:30:04+00:00  1341510046929346566   \n",
       "2      1542153431401521153 2022-06-29 14:30:04+00:00  1469115605257048064   \n",
       "3      1542153431137361923 2022-06-29 14:30:04+00:00             42459902   \n",
       "4      1542153429098831873 2022-06-29 14:30:03+00:00  1395125418651435011   \n",
       "...                    ...                       ...                  ...   \n",
       "18642  1544447539071619073 2022-07-05 22:26:02+00:00            346927346   \n",
       "18643  1544447519601479680 2022-07-05 22:25:57+00:00             58943137   \n",
       "18644  1544447517965926401 2022-07-05 22:25:57+00:00           1443602071   \n",
       "18645  1544447516057501696 2022-07-05 22:25:56+00:00   727669276207923200   \n",
       "18646  1544447506188324864 2022-07-05 22:25:54+00:00             67869026   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                        text  \\\n",
       "0                                                                                                                                                                                                                                                                          @Jouberth19 #com Bolsonaro juntos   \n",
       "1                                                                                                                                                                                           Toyjo: “Desde o início do governo Bolsonaro, Brasil recebeu cerca de R$ ... https://t.co/lADVL6POXT via @YouTube   \n",
       "2                                                                                                                                                                @Eduardomg_95 Isso aqui que é fazer um Governo sem roubalheira ou corrupção. Governo Bolsonaro! Bolsonaro reeleito. https://t.co/64Wx5beI4Q   \n",
       "3                                                                                                                                                                                                                                DESMENTINDO BOLSONARO \n",
       "Serviço de Utilidade Pública https://t.co/pv8ekLSo7W   \n",
       "4      @UOLNoticias Acho engraçado os bolsominions justificando que é pra atingir o governo Bolsonaro. Faz o seguinte, põe sua mãe ou sua filha pra trabalhar com ele então e deixa ele colocar as mãos nas partes íntimas delas, depois justifica que elas estão reclamando pra atingir o governo Bolsonaro   \n",
       "...                                                                                                                                                                                                                                                                                                      ...   \n",
       "18642                                                                                                                                            @lsentoes1 Será que o mito também não estaria pensando assim? O Lula veio na frente e Jair acabou perdendo o contato. E olha que o Jair sair primeiro heim.   \n",
       "18643                                                                                            @Anaceli65806423 @ThiagoResiste Pelo mesmo motivo ao qual o Lula não foi preso antes.. imunidade parlamentar.\n",
       "Mas não se preocupe. Todos eles dividirão celas em breve...lula dorme embaixo e bozo em cima.   \n",
       "18644                                                                                                                                                                                                                        Coloca guardiões do Lula nisso\n",
       "#STFOrganizacaoCriminosa https://t.co/lJAy31dbe9   \n",
       "18645                                                                                                                                                                                                                                                 @JanainaDoBrasil Eu tb elogio o presidente Lula assim.   \n",
       "18646                                                                                   Os mesmos que querem que eu tenha empatia com Mario Frias sāo aqueles que comemoraram a morte do neto de Lula e de Dona Marisa Leticia. Vāo pro o inferno demônios Bolsonaristas! Nāo tenho empatia por nazifacista!   \n",
       "\n",
       "               place_id    subject  is_retweet created_at_date  \\\n",
       "0      97bcdfca1a2dca59  bolsonaro           0      2022-06-29   \n",
       "1                  <NA>  bolsonaro           0      2022-06-29   \n",
       "2                  <NA>  bolsonaro           0      2022-06-29   \n",
       "3      68e019afec7d0ba5  bolsonaro           0      2022-06-29   \n",
       "4                  <NA>  bolsonaro           0      2022-06-29   \n",
       "...                 ...        ...         ...             ...   \n",
       "18642              <NA>       lula           0      2022-07-05   \n",
       "18643              <NA>       lula           0      2022-07-05   \n",
       "18644              <NA>       lula           0      2022-07-05   \n",
       "18645              <NA>       lula           0      2022-07-05   \n",
       "18646              <NA>       lula           0      2022-07-05   \n",
       "\n",
       "      created_at_time emoji lang  \\\n",
       "0            14:30:05   NaN   pt   \n",
       "1            14:30:04   NaN   pt   \n",
       "2            14:30:04   NaN   pt   \n",
       "3            14:30:04   NaN   pt   \n",
       "4            14:30:03   NaN   pt   \n",
       "...               ...   ...  ...   \n",
       "18642        22:26:02   NaN   pt   \n",
       "18643        22:25:57   NaN   pt   \n",
       "18644        22:25:57   NaN   pt   \n",
       "18645        22:25:56   NaN   pt   \n",
       "18646        22:25:54   NaN   pt   \n",
       "\n",
       "                                                                                                                                                                                                                       tokens  \n",
       "0                                                                                                                                                                                                          [bolsonaro, junto]  \n",
       "1                                                                                                                                            [tojo, desde, início, governo, bolsonaro, brasil, receber, cerca, real, youtube]  \n",
       "2                                                                                                                                            [aqui, governo, roubalheira, corrupção, governo, bolsonaro, bolsonaro, reeleger]  \n",
       "3                                                                                                                                                                       [desmentindo, bolsonaro, serviço, utilidade, pública]  \n",
       "4      [monotipia, achar, engraçar, homofóbicos, justificar, atingir, governo, bolsonaro, faz, seguinte, pôr, mãe, filha, trabalhar, deixar, colocar, mão, partes, íntima, justificar, reclamar, atingir, governo, bolsonaro]  \n",
       "...                                                                                                                                                                                                                       ...  \n",
       "18642                                                                                                                   [mito, pensar, assim, lula, frente, jair, acabar, perder, contato, olhar, jair, sair, primeiro, heim]  \n",
       "18643                                                                                 [thiagoresiste, motivo, lula, prender, antes, imunidade, parlamentar, preocupe, dividir, cela, breve, lula, dorme, embaixo, bozó, cima]  \n",
       "18644                                                                                                                                                                      [colocar, guardião, lula, stforganizacaocriminoso]  \n",
       "18645                                                                                                                                                                      [janainadobrasil, elogio, presidente, lula, assim]  \n",
       "18646                                                                          [empatar, mario, frias, comemorar, morte, neto, lula, dona, marisa, letícia, vão, inferno, demônio, bolsonaristas, neo, empatar, nazifascista]  \n",
       "\n",
       "[18647 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbb48d45cdeafec3ab5bc02a1771fe267cca3674dfe2dea2fac9d9ad5e5aebaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
